'use client'

import { useEffect, useRef } from 'react'

interface Props {
  isRecording: boolean
  isArmed: boolean
  width: number
  height: number
  currentTime: number   // å…¨å±€æ’­æ”¾å¤´æ—¶é—´ï¼ˆç§’ï¼‰
  duration: number      // é¢„è®¡å½•éŸ³æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
}

export default function RealTimeWaveform ({
  isRecording,
  isArmed,
  width,
  height,
  currentTime,
  duration
}: Props) {
  const canvasRef       = useRef<HTMLCanvasElement | null>(null)
  const ctxRef          = useRef<CanvasRenderingContext2D | null>(null)

  const audioCtxRef     = useRef<AudioContext | null>(null)
  const streamRef       = useRef<MediaStream | null>(null)
  const workletRef      = useRef<AudioWorkletNode | null>(null)

  /** æ¯ä¸ªåƒç´ ä½ç½®çš„ min / maxï¼ˆ-1â€Šâ†’â€Š1ï¼‰ */
  const minArrRef = useRef<Float32Array>(new Float32Array(width).fill(0))
  const maxArrRef = useRef<Float32Array>(new Float32Array(width).fill(0))
  const lastXRef  = useRef<number>(-1)

  /* ---------- å½•éŸ³å¼€å…³ ---------- */
  useEffect(() => {
    if (isRecording && isArmed) {
      initAudio().catch(console.error)
    } else {
      cleanup()
    }
    return cleanup
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isRecording, isArmed])

  /* ---------- å¤§å°å˜åŒ–æ—¶é‡æ–°åˆ†é…æ•°ç»„ ---------- */
  useEffect(() => {
    minArrRef.current = new Float32Array(width).fill(0)
    maxArrRef.current = new Float32Array(width).fill(0)
    draw()
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [width, height])

  /* ---------- åœæ­¢å½•éŸ³åï¼Œä¾æ—§æ ¹æ® currentTime é‡ç»˜æ’­æ”¾å¤´ ---------- */
  useEffect(draw, [currentTime]) // eslint-disable-line react-hooks/exhaustive-deps

  /* ---------- åˆå§‹åŒ– Audio & Worklet ---------- */
  async function initAudio () {
    if (audioCtxRef.current) return                       // å·²åœ¨å½•

    // 1. éº¦å…‹é£æµ
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    streamRef.current = stream

    // 2. AudioContext
    const ctx = new (window.AudioContext || (window as any).webkitAudioContext)()
    await ctx.resume()
    audioCtxRef.current = ctx

    // 3. Worklet
    await ctx.audioWorklet.addModule('/waveform-processor.js')
    const worklet = new AudioWorkletNode(ctx, 'waveform-processor')
    worklet.port.onmessage = (ev) => {
      const { time, min, max } = ev.data as { time: number; min: number; max: number }
      updateWaveform(time, min, max)
    }
    workletRef.current = worklet

    // 4. è¿æ¥èŠ‚ç‚¹
    const src = ctx.createMediaStreamSource(stream)
    const mute = ctx.createGain()
    mute.gain.value = 0                                   // é™éŸ³ï¼Œé¿å…å›æ”¾
    src.connect(worklet).connect(mute).connect(ctx.destination)

    console.log('ğŸ™  audio worklet started')
  }

  /* ---------- æ›´æ–°æ³¢å½¢æ•°ç»„ ---------- */
  function updateWaveform (time: number, min: number, max: number) {
    if (!duration) return
    const x = Math.floor((time / duration) * width)
    if (x < 0 || x >= width) return

    minArrRef.current[x] = Math.min(minArrRef.current[x] || 0, min)
    maxArrRef.current[x] = Math.max(maxArrRef.current[x] || 0, max)
    lastXRef.current = Math.max(lastXRef.current, x)

    draw()
  }

  /* ---------- ç»˜åˆ¶ ---------- */
  function draw () {
    const canvas = canvasRef.current
    if (!canvas) return

    // Hiâ€‘DPI å¤„ç†
    const dpr = window.devicePixelRatio || 1
    canvas.width  = width  * dpr
    canvas.height = height * dpr
    canvas.style.width  = `${width}px`
    canvas.style.height = `${height}px`

    let ctx = ctxRef.current
    if (!ctx) {
      ctx = canvas.getContext('2d')!
      ctxRef.current = ctx
    }
    ctx.save()
    ctx.scale(dpr, dpr)

    // èƒŒæ™¯
    ctx.clearRect(0, 0, width, height)

    const minArr = minArrRef.current
    const maxArr = maxArrRef.current
    const lastX  = lastXRef.current
    if (lastX < 1) {                        // æš‚æ— æœ‰æ•ˆæ•°æ®
      ctx.restore()
      return
    }

    const midY = height / 2
    const amp  = height * 0.48              // ç¼©æ”¾ç³»æ•°

    /* ---- å¡«å……åŒ…ç»œå¸¦ ---- */
    ctx.beginPath()
    ctx.moveTo(0, midY - (maxArr[0] ?? 0) * amp)
    for (let x = 1; x <= lastX; x++) {
      ctx.lineTo(x, midY - (maxArr[x] ?? 0) * amp)
    }
    for (let x = lastX; x >= 0; x--) {
      ctx.lineTo(x, midY - (minArr[x] ?? 0) * amp)
    }
    ctx.closePath()
    ctx.fillStyle = '#3fa0ff'
    ctx.fill()

    /* ---- æ’­æ”¾å¤´ â€”â€” çº¢çº¿ ---- */
    const playX = Math.floor((currentTime / duration) * width)
    ctx.strokeStyle = '#ff4d4f'
    ctx.lineWidth   = 1 / dpr
    ctx.beginPath()
    ctx.moveTo(playX + 0.5, 0)
    ctx.lineTo(playX + 0.5, height)
    ctx.stroke()

    ctx.restore()
  }

  /* ---------- æ¸…ç†èµ„æº ---------- */
  function cleanup () {
    workletRef.current?.disconnect()
    workletRef.current?.port.close()
    workletRef.current = null

    streamRef.current?.getTracks().forEach(t => t.stop())
    streamRef.current = null

    audioCtxRef.current?.close()
    audioCtxRef.current = null
  }

  return <canvas ref={canvasRef} />
}